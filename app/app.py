import streamlit as st
import sys
import os
import asyncio
import json

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from core.chat.chat_session import ChatSession

st.set_page_config(page_title="LangGraph MCP Agent", layout="wide")

# æ¨¡å‹é€‰æ‹©
st.sidebar.markdown("### æ¨¡å‹é€‰æ‹©")
available_models = ["deepseek-chat", "deepseek-reasoner"]

# åˆå§‹åŒ–é»˜è®¤æ¨¡å‹
if "selected_model" not in st.session_state:
    st.session_state.selected_model = "deepseek-chat"

# é€‰æ‹©æ¨¡å‹
selected_model = st.sidebar.selectbox("è¯·é€‰æ‹©æ¨¡å‹", available_models, index=available_models.index(st.session_state.selected_model))

# åˆ‡æ¢æ¨¡å‹
if selected_model != st.session_state.selected_model:
    st.session_state.selected_model = selected_model
    st.session_state.session = ChatSession(model_name=selected_model)
    st.experimental_rerun()

# çŠ¶æ€åˆå§‹åŒ–
if "thought_history" not in st.session_state:
    st.session_state.thought_history = []

if "session" not in st.session_state:
    st.session_state.session = ChatSession(model_name=st.session_state.selected_model)

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if "workflow_steps" not in st.session_state:
    st.session_state.workflow_steps = []  # ç”¨æ¥å­˜å‚¨å·¥å…·è°ƒç”¨å·¥ä½œæµç®€åŒ–ä¿¡æ¯

# MCP Promptç¼“å­˜
if "all_prompts" not in st.session_state:
    prompts = asyncio.run(st.session_state.session.list_all_prompts())
    # prompts æ˜¯ List[(name, args_schema)]
    st.session_state.all_prompts = prompts

st.title("ğŸ§ LangGraph MCP Agent")

# åŠ è½½èµ„æºåˆ—è¡¨
if "resource_uris" not in st.session_state:
    st.session_state.resource_uris = []

if "all_resource_uris" not in st.session_state:
    uris = asyncio.run(st.session_state.session.list_all_resources())
    print(f"åŠ è½½åˆ° {len(uris)} ä¸ªèµ„æº")
    st.session_state.all_resource_uris = uris

with st.sidebar:
    st.markdown("### ğŸ“‚é€‰æ‹©æ³¨å…¥èµ„æº")
    selected_uris = st.multiselect(
        "é€‰æ‹©éœ€è¦æ³¨å…¥ä¸Šä¸‹æ–‡çš„èµ„æºï¼š",
        st.session_state.all_resource_uris,
        default=st.session_state.resource_uris,
    )
    st.session_state.resource_uris = selected_uris

# æç¤ºæ¨¡ç‰ˆåç§°ä¸å‚æ•°ååˆ—è¡¨çš„æ˜ å°„
prompt_args_map = {}
for name, args in st.session_state.all_prompts:
    prompt_args_map[name] = [arg.name for arg in args] if args else []

# ä¾§è¾¹æ ï¼šèµ„æºé€‰æ‹©ã€å¿«æ·æç¤ºæ“ä½œ
with st.sidebar:
    st.markdown("### ğŸ’¡ å¿«æ·æç¤ºæ“ä½œ")

    # é€‰æ‹©æç¤ºæ¨¡æ¿
    selected_prompt = st.selectbox("é€‰æ‹©ä¸€ä¸ªæç¤ºæ¨¡æ¿", ["ï¼ˆä¸ä½¿ç”¨æç¤ºï¼‰"] + list(prompt_args_map.keys()), key="selected_prompt")

    # æ ¹æ®é€‰æ‹©è®¾ç½®å‚æ•°ååˆ—è¡¨
    if selected_prompt == "ï¼ˆä¸ä½¿ç”¨æç¤ºï¼‰":
        st.session_state.selected_prompt_args = []
    else:
        st.session_state.selected_prompt_args = prompt_args_map.get(selected_prompt, [])

    st.markdown("---")

    # ä¾§è¾¹æ æ“ä½œï¼šæ¸…ç©ºèŠå¤©ã€åˆ·æ–°å·¥å…·
    if st.button("æ¸…ç©ºèŠå¤©", use_container_width=True):
        st.session_state.chat_history = []
        st.session_state.workflow_steps = []
        st.session_state.thought_history = []
        st.session_state.session = ChatSession(model_name=st.session_state.selected_model)  # é‡å»ºä¼šè¯
        st.experimental_rerun()

    if st.button("åˆ·æ–°å·¥å…·", use_container_width=True):
        st.session_state.session = ChatSession(model_name=st.session_state.selected_model)  # é‡å»ºä¼šè¯å³åˆ·æ–°å·¥å…·
        st.session_state.workflow_steps = []
        st.experimental_rerun()

    # MCPæœåŠ¡ä¿¡æ¯å±•ç¤º
    with st.expander("å½“å‰ MCP æœåŠ¡é…ç½®", expanded=True):
        server_info = st.session_state.session.get_server_info()

        card_style = """
            <style>
            .tool-card {
                background-color: #f9f9f9;
                border-radius: 12px;
                padding: 12px 16px;
                margin-bottom: 10px;
                box-shadow: 0 2px 6px rgba(0,0,0,0.05);
            }
            .tool-name {
                font-weight: 600;
                font-size: 16px;
                color: #262730;
                margin-bottom: 6px;
            }
            .tool-transport {
                font-size: 14px;
                color: #6c757d;
            }
            .tool-transport span {
                font-weight: 500;
                background-color: #e8f0fe;
                color: #1967d2;
                padding: 2px 6px;
                border-radius: 6px;
            }
            </style>
        """
        st.markdown(card_style, unsafe_allow_html=True)

        for tool_name, config in server_info.items():
            transport = config.get("transport", "unknown")
            card_html = f"""
            <div class="tool-card">
                <div class="tool-name">{tool_name}</div>
                <div class="tool-transport"> Transport: <span>{transport}</span></div>
            </div>
            """
            st.markdown(card_html, unsafe_allow_html=True)

        st.markdown("---")
        st.markdown("###  æ·»åŠ æ–°å·¥å…·")

        new_tool_json = st.text_area(
            "è¯·è¾“å…¥æ–°å·¥å…· JSONï¼ˆé”®å+å¯¹è±¡ï¼‰",
            height=160,
            placeholder='"demo-tool": {"command": "python", "args": ["demo.py"], "transport": "stdio"}'
        )

        if st.button(" æ·»åŠ å·¥å…·å¹¶ä¿å­˜"):
            try:
                # è§£æç”¨æˆ·è¾“å…¥
                parsed = json.loads("{" + new_tool_json.strip().rstrip(",") + "}")

                # è¯»å–åŸå§‹é…ç½®
                current_config = st.session_state.session.get_server_info()
                current_config.update(parsed)

                # å†™å›é…ç½®æ–‡ä»¶
                with open(st.session_state.session.server_config_path, "w", encoding="utf-8") as f:
                    json.dump(current_config, f, indent=4, ensure_ascii=False)

                st.success(" å·¥å…·æ·»åŠ æˆåŠŸå¹¶å·²å†™å…¥é…ç½®æ–‡ä»¶ï¼")
                st.experimental_rerun()

            except Exception as e:
                st.error(f" æ·»åŠ å¤±è´¥ï¼Œè¯·æ£€æŸ¥ JSON æ ¼å¼ï¼š{e}")

# å†å²å¯¹è¯ 
for i, (user_msg, bot_msg) in enumerate(st.session_state.chat_history):
    with st.chat_message("user"):
        st.markdown(user_msg)
    with st.chat_message("assistant"):
        # æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹
        if i < len(st.session_state.thought_history):
            with st.expander("ğŸ’¡ æ€è€ƒè¿‡ç¨‹", expanded=False):
                for line in st.session_state.thought_history[i]:
                    st.markdown(f"- {line}")
        st.markdown(bot_msg)

# ç”¨æˆ·è¾“å…¥å¤„ç† 
if st.session_state.selected_prompt and st.session_state.selected_prompt_args:
    arg_count = len(st.session_state.selected_prompt_args)
    if arg_count == 1:
        placeholder_text = f"è¯·è¾“å…¥å‚æ•°ï¼ˆ{st.session_state.selected_prompt_args[0]}ï¼‰ï¼Œç³»ç»Ÿå°†æ ¹æ®å‚æ•°å†…å®¹è¡¥å……æç¤ºå¹¶ä½œç­”"
    else:
        arg_names_str = " || ".join(st.session_state.selected_prompt_args)
        placeholder_text = f"è¯·æŒ‰é¡ºåºè¾“å…¥å‚æ•°ï¼ˆ{arg_names_str}ï¼‰ï¼Œå„å‚æ•°ä¹‹é—´ç”¨ '||' åˆ†éš”ï¼Œç³»ç»Ÿå°†æ ¹æ®å‚æ•°å†…å®¹è¡¥å……æç¤ºå¹¶ä½œç­”"
else:
    placeholder_text = "è¯·è¾“å…¥ä½ çš„é—®é¢˜..."

user_input = st.chat_input(placeholder_text)

if user_input:
    st.chat_message("user").markdown(user_input)

    with st.chat_message("assistant"):
        with st.spinner("æ­£åœ¨æ€è€ƒä¸­..."):
            response_box = {"response": ""}
            thought_buffer = []

            with st.expander("ğŸ’¡ æ€è€ƒè¿‡ç¨‹", expanded=True):
                thought_container = st.empty()

                async def handle():
                    prompt_name = st.session_state.get("selected_prompt")
                    arg_names = st.session_state.get("selected_prompt_args", [])

                    # è§£æå‚æ•°
                    if prompt_name and arg_names:
                        parts = [part.strip() for part in user_input.split("||")]
                        args_dict = dict(zip(arg_names, parts))
                    else:
                        args_dict = {}

                    async for etype, content in st.session_state.session.stream_with_trace(
                        user_input,
                        resource_uris=st.session_state.resource_uris,
                        prompt_injection=prompt_name,
                        prompt_args=args_dict
                    ):
                        if etype in {"llm_thinking", "tool_call", "tool_result"}:
                            icon_map = {
                                "llm_thinking": "ğŸ’­",
                                "tool_call": "[å·¥å…·è°ƒç”¨]",
                                "tool_result": "[å·¥å…·è¿”å›]",
                            }
                            icon = icon_map.get(etype, "-")
                            line = f"{icon} {content}"
                            thought_buffer.append(line)
                            thought_container.markdown(
                                "\n".join(f"- {line}" for line in thought_buffer),
                                unsafe_allow_html=True
                            )
                        elif etype == "final_response":
                            response_box["response"] = content

                asyncio.run(handle())

            st.markdown(response_box["response"])

            # ä¿å­˜èŠå¤©å†å²
            st.session_state.chat_history.append((user_input, response_box["response"]))
            st.session_state.thought_history.append(thought_buffer)
            st.session_state.workflow_steps.append([])
