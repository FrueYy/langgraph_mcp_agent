import streamlit as st
import sys
import os
import asyncio

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from core.chat.chat_session import ChatSession

st.set_page_config(page_title="LangGraph MCP Agent", layout="wide")

# çŠ¶æ€åˆå§‹åŒ–
if "thought_history" not in st.session_state:
    st.session_state.thought_history = []

if "session" not in st.session_state:
    st.session_state.session = ChatSession()

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if "workflow_steps" not in st.session_state:
    st.session_state.workflow_steps = []  # ç”¨æ¥å­˜å‚¨å·¥å…·è°ƒç”¨å·¥ä½œæµç®€åŒ–ä¿¡æ¯

st.title("ğŸ§  LangGraph MCP Agent")

# ä¾§è¾¹æ æ“ä½œ
with st.sidebar:
    if st.button("ğŸ§¹ æ¸…ç©ºèŠå¤©", use_container_width=True):
        st.session_state.chat_history = []
        st.session_state.workflow_steps = []
        st.session_state.thought_history = []
        st.session_state.session = ChatSession()  # é‡å»ºä¼šè¯
        st.experimental_rerun()

    if st.button("ğŸ”„ åˆ·æ–°å·¥å…·", use_container_width=True):
        st.session_state.session = ChatSession()  # é‡å»ºä¼šè¯å³åˆ·æ–°å·¥å…·
        st.session_state.workflow_steps = []
        st.experimental_rerun()

    # MCP æœåŠ¡ä¿¡æ¯å±•ç¤º
    with st.expander("ğŸ› ï¸ å½“å‰ MCP æœåŠ¡é…ç½®", expanded=False):
        st.json(st.session_state.session.get_server_info())

# æ˜¾ç¤ºå†å²å¯¹è¯
for i, (user_msg, bot_msg) in enumerate(st.session_state.chat_history):
    with st.chat_message("user"):
        st.markdown(user_msg)
    with st.chat_message("assistant"):
        # æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹
        if i < len(st.session_state.thought_history):
            with st.expander("ğŸ’¡ æ€è€ƒè¿‡ç¨‹", expanded=False):
                for line in st.session_state.thought_history[i]:
                    st.markdown(f"- {line}")
        st.markdown(bot_msg)

# å¤„ç†ç”¨æˆ·è¾“å…¥
user_input = st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜...")

if user_input:
    st.chat_message("user").markdown(user_input)

    with st.chat_message("assistant"):
        with st.spinner("æ­£åœ¨æ€è€ƒä¸­..."):
            response_box = {"response": ""}
            trace_lines = []
            thought_buffer = []

            with st.expander("ğŸ’¡ æ€è€ƒè¿‡ç¨‹", expanded=True):
                thought_container = st.empty()  # åœ¨expanderå†…æµå¼æ›´æ–°

                async def handle():
                    async for etype, content in st.session_state.session.stream_with_trace(user_input):
                        if etype in {"llm_thinking", "tool_call", "tool_result"}:
                            icon_map = {
                                "llm_thinking": "ğŸ’­",
                                "tool_call": "[å·¥å…·è°ƒç”¨]",
                                "tool_result": "[å·¥å…·è¿”å›]",
                            }
                            icon = icon_map.get(etype, "-")
                            line = f"{icon} {content}"
                            thought_buffer.append(line)

                            # å®æ—¶åˆ·æ–°å†…å®¹
                            thought_container.markdown(
                                "\n".join(f"- {line}" for line in thought_buffer),
                                unsafe_allow_html=True
                            )
                        elif etype == "final_response":
                            response_box["response"] = content
                        elif etype == "trace_tree":
                            trace_lines.extend(content)

                asyncio.run(handle())

            # è¾“å‡ºæœ€ç»ˆå›å¤
            st.markdown(response_box["response"])

            # ä¿å­˜åˆ°å†å²çŠ¶æ€
            st.session_state.chat_history.append((user_input, response_box["response"]))
            st.session_state.thought_history.append(thought_buffer)
            st.session_state.workflow_steps.append(trace_lines)



